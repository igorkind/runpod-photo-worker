import sys
import runpod
import torch
import requests
import base64
import io
import cv2
import numpy as np
import traceback
import diffusers
import transformers

print(f"DEBUG: Script v1.16 (Quality Boost). Diffusers: {diffusers.__version__}", file=sys.stderr)

from PIL import Image
from diffusers import StableDiffusionXLInpaintPipeline, StableDiffusionXLImg2ImgPipeline, DPMSolverMultistepScheduler
from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
pipe_base = None
pipe_style = None
processor = None
segmentator = None

def init_handler():
    global pipe_base, pipe_style, processor, segmentator
    
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üöÄ Initializing handler on {device}...")

        # 1. ClipSeg
        processor = CLIPSegProcessor.from_pretrained("CIDAS/clipseg-rd64-refined")
        segmentator = CLIPSegForImageSegmentation.from_pretrained("CIDAS/clipseg-rd64-refined").to(device)

        # 2. Base Inpainting
        print("Loading Base Model...")
        pipe_base = StableDiffusionXLInpaintPipeline.from_pretrained(
            "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
            torch_dtype=torch.float16,
            variant="fp16",
            use_safetensors=True
        ).to(device)
        
        # üî• –í–ê–ñ–ù–û: –°—Ç–∞–≤–∏–º DPM++ 2M Karras Scheduler (–î–ª—è —á–µ—Ç–∫–æ—Å—Ç–∏)
        pipe_base.scheduler = DPMSolverMultistepScheduler.from_config(
            pipe_base.scheduler.config, use_karras_sigmas=True
        )

        # 3. Big Love (Style)
        print("Loading Style Model...")
        pipe_style = StableDiffusionXLImg2ImgPipeline.from_single_file(
            "./checkpoints/Biglove2.safetensors",
            torch_dtype=torch.float16,
            use_safetensors=True
        ).to(device)
        
        # –¢–æ–∂–µ —Å—Ç–∞–≤–∏–º DPM++ Scheduler
        pipe_style.scheduler = DPMSolverMultistepScheduler.from_config(
            pipe_style.scheduler.config, use_karras_sigmas=True
        )
        
        print("‚úÖ Initialization complete (High Quality Mode).")
        
    except Exception as e:
        print(f"üî• CRITICAL ERROR: {e}")
        traceback.print_exc()
        import time
        time.sleep(10)
        raise e

def smart_resize(image, target_size=1024):
    """
    –£–º–Ω—ã–π —Ä–µ—Å–∞–π–∑: 
    1. –ï—Å–ª–∏ —Ñ–æ—Ç–æ –º–∞–ª–µ–Ω—å–∫–æ–µ -> —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç (Upscale) –¥–æ ~1024 –ø–æ –±–æ–ª—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ.
    2. –ï—Å–ª–∏ —Ñ–æ—Ç–æ –æ–≥—Ä–æ–º–Ω–æ–µ -> —É–º–µ–Ω—å—à–∞–µ—Ç –¥–æ 1024.
    3. –î–µ–ª–∞–µ—Ç —Å—Ç–æ—Ä–æ–Ω—ã –∫—Ä–∞—Ç–Ω—ã–º–∏ 8.
    """
    width, height = image.size
    aspect_ratio = width / height
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–≤—É—é —à–∏—Ä–∏–Ω—É –∏ –≤—ã—Å–æ—Ç—É, —Å—Ç—Ä–µ–º—è—Å—å –∫ target_size
    if width > height:
        new_width = target_size
        new_height = int(target_size / aspect_ratio)
    else:
        new_height = target_size
        new_width = int(target_size * aspect_ratio)
        
    # –û–∫—Ä—É–≥–ª—è–µ–º –¥–æ 8
    new_width = (new_width // 8) * 8
    new_height = (new_height // 8) * 8
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º LANCZOS –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
    return image.resize((new_width, new_height), Image.LANCZOS)

def get_mask(image, text_prompts):
    device = segmentator.device
    prompts = [p.strip() for p in text_prompts.split(",")]
    inputs = processor(text=prompts, images=[image] * len(prompts), padding="max_length", return_tensors="pt").to(device)
    with torch.no_grad():
        outputs = segmentator(**inputs)
    preds = outputs.logits.unsqueeze(1)
    combined_mask = torch.sigmoid(preds[0][0])
    for i in range(1, len(prompts)):
        combined_mask = torch.max(combined_mask, torch.sigmoid(preds[i][0]))
    mask_np = combined_mask.cpu().numpy()
    mask_cv = cv2.resize(mask_np, image.size, interpolation=cv2.INTER_CUBIC)
    _, binary_mask = cv2.threshold(mask_cv, 0.3, 255, cv2.THRESH_BINARY)
    return Image.fromarray(binary_mask.astype(np.uint8))

def download_image(url):
    response = requests.get(url, timeout=30)
    response.raise_for_status()
    return Image.open(io.BytesIO(response.content)).convert("RGB")

def handler(event):
    global pipe_base, pipe_style
    
    job_id = event.get("id", "local_test")
    print(f"üé¨ Starting job: {job_id}")

    job_input = event["input"]
    image_url = job_input.get("image_url")
    prompt = job_input.get("prompt")
    # –î–æ–±–∞–≤–ª—è–µ–º "–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ" –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è Big Love
    negative_prompt = job_input.get("negative_prompt", "drawing, painting, illustration, render, 3d, cartoon, anime, low quality, blurry, deformed, ugly, bad anatomy, bad hands, text, watermark")
    
    if not image_url or not prompt:
        return {"status": "failed", "error": "Missing input"}

    try:
        generator = None
        if "seed" in job_input:
             generator = torch.Generator(device="cuda").manual_seed(job_input["seed"])

        print(f"üé® Processing: {image_url}")
        
        # 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ Upscaling
        original_image = download_image(image_url)
        processing_image = smart_resize(original_image, target_size=1024) # <-- –§–æ—Ä—Å–∏—Ä—É–µ–º 1024px
        print(f"üìè Resized to: {processing_image.size}")
        
        mask_target = job_input.get("mask_target", "clothes, dress, suit, tshirt, swimsuit, lingerie, underwear, bra, panties")
        mask_image = get_mask(processing_image, mask_target)
        
        # 2. –≠–¢–ê–ü 1: Base Inpainting (–°—Ç—Ä—É–∫—Ç—É—Ä–∞)
        print("üîπ Stage 1: Base Structure...")
        inpainted_image = pipe_base(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=processing_image,
            mask_image=mask_image,
            height=processing_image.height,
            width=processing_image.width,
            num_inference_steps=25,  # –ë–æ–ª—å—à–µ —à–∞–≥–æ–≤ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
            guidance_scale=5.0,      # <-- –°–Ω–∏–∂–∞–µ–º CFG –¥–ª—è —Ä–µ–∞–ª–∏–∑–º–∞ (–±—ã–ª–æ 7.5)
            strength=0.99,
            generator=generator
        ).images[0]
        
        # 3. –≠–¢–ê–ü 2: Refiner Big Love (–î–µ—Ç–∞–ª–∏)
        print("üî∏ Stage 2: Big Love Finish...")
        final_image = pipe_style(
            prompt=prompt, # –¢–æ—Ç –∂–µ –ø—Ä–æ–º–ø—Ç
            negative_prompt=negative_prompt,
            image=inpainted_image,
            num_inference_steps=25,
            strength=0.50,       # –ß—É—Ç—å —Å–∏–ª—å–Ω–µ–µ –ø–µ—Ä–µ—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º (–±—ã–ª–æ 0.35)
            guidance_scale=5.0,  # <-- –¢–æ–∂–µ 5.0
            generator=generator
        ).images[0]

        buffered = io.BytesIO()
        final_image.save(buffered, format="JPEG", quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        
        return {"status": "success", "image": img_str}
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        traceback.print_exc()
        return {"status": "failed", "error": str(e)}

init_handler()
runpod.serverless.start({"handler": handler})