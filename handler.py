import sys
import runpod
import torch
import requests
import base64
import io
import cv2
import numpy as np
import traceback
import diffusers
import transformers

print(f"DEBUG: Script v2.0 (Smart Masking + Compositing). Diffusers: {diffusers.__version__}", file=sys.stderr)

from PIL import Image, ImageFilter
from diffusers import StableDiffusionXLInpaintPipeline, StableDiffusionXLImg2ImgPipeline, DPMSolverMultistepScheduler
from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
pipe_base = None
pipe_style = None
processor = None
segmentator = None

def init_handler():
    global pipe_base, pipe_style, processor, segmentator
    
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üöÄ Initializing handler on {device}...")

        # 1. ClipSeg (–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è)
        processor = CLIPSegProcessor.from_pretrained("CIDAS/clipseg-rd64-refined")
        segmentator = CLIPSegForImageSegmentation.from_pretrained("CIDAS/clipseg-rd64-refined").to(device)

        # 2. Base Inpainting (–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å - –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã)
        print("Loading Base Model...")
        pipe_base = StableDiffusionXLInpaintPipeline.from_pretrained(
            "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
            torch_dtype=torch.float16,
            variant="fp16",
            use_safetensors=True
        ).to(device)
        
        # DPM++ Scheduler –¥–ª—è —á–µ—Ç–∫–æ—Å—Ç–∏
        pipe_base.scheduler = DPMSolverMultistepScheduler.from_config(
            pipe_base.scheduler.config, use_karras_sigmas=True
        )

        # 3. Big Love (–°—Ç–∏–ª—å - —á–µ—Ä–µ–∑ Img2Img)
        print("Loading Style Model...")
        pipe_style = StableDiffusionXLImg2ImgPipeline.from_single_file(
            "./checkpoints/Biglove2.safetensors",
            torch_dtype=torch.float16,
            use_safetensors=True
        ).to(device)
        
        pipe_style.scheduler = DPMSolverMultistepScheduler.from_config(
            pipe_style.scheduler.config, use_karras_sigmas=True
        )
        
        print("‚úÖ Initialization complete.")
        
    except Exception as e:
        print(f"üî• CRITICAL ERROR: {e}")
        traceback.print_exc()
        import time
        time.sleep(10)
        raise e

def smart_resize(image, target_size=1024):
    """–£–º–Ω—ã–π —Ä–µ—Å–∞–π–∑ –¥–æ ~1024px –ø–æ –±–æ–ª—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ."""
    width, height = image.size
    aspect_ratio = width / height
    
    if width > height:
        new_width = target_size
        new_height = int(target_size / aspect_ratio)
    else:
        new_height = target_size
        new_width = int(target_size * aspect_ratio)
        
    new_width = (new_width // 8) * 8
    new_height = (new_height // 8) * 8
    
    return image.resize((new_width, new_height), Image.LANCZOS)

def get_mask_advanced(image, include_prompts, exclude_prompts):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–∞—Å–∫—É: (Include - Exclude).
    –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–¥–µ–ª–∏—Ç—å '–æ–¥–µ–∂–¥—É', –Ω–æ –≤—ã—á–µ—Å—Ç—å '–ª–∏—Ü–æ' –∏ '—Ä—É–∫–∏'.
    """
    device = segmentator.device
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
    targets = [p.strip() for p in include_prompts.split(",")]
    anti_targets = [p.strip() for p in exclude_prompts.split(",")] if exclude_prompts else []
    
    all_prompts = targets + anti_targets
    
    inputs = processor(text=all_prompts, images=[image] * len(all_prompts), padding="max_length", return_tensors="pt").to(device)
    
    with torch.no_grad():
        outputs = segmentator(**inputs)
        
    preds = outputs.logits.unsqueeze(1)
    
    # 1. –°–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—Å—ë, —á—Ç–æ –Ω—É–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å (–û–¥–µ–∂–¥–∞)
    mask_include = torch.sigmoid(preds[0][0])
    for i in range(1, len(targets)):
        mask_include = torch.max(mask_include, torch.sigmoid(preds[i][0]))
        
    # 2. –°–∫–ª–∞–¥—ã–≤–∞–µ–º –≤—Å—ë, —á—Ç–æ –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å (–õ–∏—Ü–æ, —Ä—É–∫–∏)
    if anti_targets:
        mask_exclude = torch.sigmoid(preds[len(targets)][0])
        for i in range(len(targets) + 1, len(all_prompts)):
            mask_exclude = torch.max(mask_exclude, torch.sigmoid(preds[i][0]))
        
        # 3. –í—ã—á–∏—Ç–∞–µ–º: –û–¥–µ–∂–¥–∞ –ú–ò–ù–£–° –õ–∏—Ü–æ
        final_mask_tensor = mask_include - (mask_exclude * 1.2) # –£—Å–∏–ª–∏–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
        final_mask_tensor = torch.clamp(final_mask_tensor, 0, 1)
    else:
        final_mask_tensor = mask_include

    mask_np = final_mask_tensor.cpu().numpy()
    mask_cv = cv2.resize(mask_np, image.size, interpolation=cv2.INTER_CUBIC)
    
    # –ü–æ—Ä–æ–≥ —á—É—Ç—å –≤—ã—à–µ (0.35), —á—Ç–æ–±—ã –Ω–µ —Ü–µ–ø–ª—è—Ç—å —Ñ–æ–Ω
    _, binary_mask = cv2.threshold(mask_cv, 0.35, 255, cv2.THRESH_BINARY)
    return Image.fromarray(binary_mask.astype(np.uint8))

def download_image(url):
    response = requests.get(url, timeout=30)
    response.raise_for_status()
    return Image.open(io.BytesIO(response.content)).convert("RGB")

def handler(event):
    global pipe_base, pipe_style
    
    job_id = event.get("id", "local_test")
    print(f"üé¨ Starting job: {job_id}")

    job_input = event["input"]
    image_url = job_input.get("image_url")
    prompt = job_input.get("prompt")
    negative_prompt = job_input.get("negative_prompt", "drawing, painting, illustration, render, 3d, cartoon, anime, low quality, blurry, deformed, ugly, bad anatomy, bad hands, text, watermark")
    
    if not image_url or not prompt:
        return {"status": "failed", "error": "Missing input"}

    try:
        generator = None
        if "seed" in job_input:
             generator = torch.Generator(device="cuda").manual_seed(job_input["seed"])

        print(f"üé® Processing: {image_url}")
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
        original_image = download_image(image_url)
        processing_image = smart_resize(original_image, target_size=1024)
        
        # 2. –£–º–Ω–∞—è –ú–∞—Å–∫–∞
        # –ò—â–µ–º –æ–¥–µ–∂–¥—É, –Ω–æ –Ø–í–ù–û –∏—Å–∫–ª—é—á–∞–µ–º –ª–∏—Ü–æ –∏ —Ä—É–∫–∏
        mask_target = job_input.get("mask_target", "clothes, dress, suit, tshirt, swimsuit, lingerie, underwear, bra, panties, dress, suit, tshirt, outfit")
        mask_exclude = "face, head, hands, skin" 
        
        print(f"üé≠ Generating mask: +[{mask_target}] -[{mask_exclude}]")
        mask_image = get_mask_advanced(processing_image, mask_target, mask_exclude)
        
        # –†–∞–∑–º—ã–≤–∞–µ–º –º–∞—Å–∫—É –¥–ª—è –º—è–≥–∫–∏—Ö –∫—Ä–∞–µ–≤ (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ —ç—Ñ—Ñ–µ–∫—Ç–∞ "–∞–ø–ø–ª–∏–∫–∞—Ü–∏–∏")
        mask_blurred = mask_image.filter(ImageFilter.GaussianBlur(radius=5))

        # 3. –≠–¢–ê–ü 1: Base Inpainting (–ó–∞–º–µ–Ω—è–µ–º –æ–¥–µ–∂–¥—É, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ–∑—É)
        print("üîπ Stage 1: Base Structure...")
        # –ú–∞—Å–∫–∞ —á–µ—Ä–Ω–∞—è –¥–ª—è –ª–∏—Ü–∞ -> –º–æ–¥–µ–ª—å –µ–≥–æ –Ω–µ —Ç—Ä–æ–≥–∞–µ—Ç
        inpainted_image = pipe_base(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=processing_image,
            mask_image=mask_image, # –ñ–µ—Å—Ç–∫–∞—è –º–∞—Å–∫–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            height=processing_image.height,
            width=processing_image.width,
            num_inference_steps=25,
            guidance_scale=5.0,
            strength=0.99,
            generator=generator
        ).images[0]
        
        # 4. –≠–¢–ê–ü 2: Big Love (–°—Ç–∏–ª—å)
        print("üî∏ Stage 2: Big Love Styling...")
        # –ü—Ä–æ–≥–æ–Ω—è–µ–º –í–°–Æ –∫–∞—Ä—Ç–∏–Ω–∫—É —á–µ—Ä–µ–∑ —Å—Ç–∞–π–ª–µ—Ä
        style_image = pipe_style(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=inpainted_image,
            num_inference_steps=25,
            strength=0.45, # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–∏–ª—å–Ω–æ, —á—Ç–æ–±—ã –Ω–∞–ª–æ–∂–∏—Ç—å —Ç–µ–∫—Å—Ç—É—Ä—ã —Ç–∫–∞–Ω–∏
            guidance_scale=5.0,
            generator=generator
        ).images[0]

        # 5. –≠–¢–ê–ü 3: –ö–æ–º–ø–æ–∑–∏—Ç–∏–Ω–≥ (–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ª–∏—Ü–∞)
        print("üîß Stage 3: Face Restoration (Compositing)...")
        # –ú—ã –±–µ—Ä–µ–º style_image —Ç–∞–º, –≥–¥–µ –±—ã–ª–∞ –æ–¥–µ–∂–¥–∞ (mask), 
        # –∏ inpainted_image (–≥–¥–µ –ª–∏—Ü–æ –Ω–µ—Ç—Ä–æ–Ω—É—Ç–æ) —Ç–∞–º, –≥–¥–µ –º–∞—Å–∫–∏ –Ω–µ—Ç.
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–º—ã—Ç—É—é –º–∞—Å–∫—É –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞.
        final_image = Image.composite(style_image, inpainted_image, mask_blurred)

        # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        buffered = io.BytesIO()
        final_image.save(buffered, format="JPEG", quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")
        
        print(f"‚úÖ Job {job_id} success.")
        return {"status": "success", "image": img_str}
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        traceback.print_exc()
        return {"status": "failed", "error": str(e)}

init_handler()
runpod.serverless.start({"handler": handler})